{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53587aef",
   "metadata": {},
   "source": [
    "# 1.1 Introduction to Regression\n",
    "\n",
    "The goal of regression analysis is to provide accurate mapping from one or\n",
    "more input variables (called features in machine learning or exogenous\n",
    "variables in econometrics) to a continuous output variable (called the label or\n",
    "target in machine learning and the endogenous variable in\n",
    "econometrics).\n",
    "\n",
    "In this lecture, we will study some of the most fundamental and widely-used\n",
    "regression algorithms.\n",
    "\n",
    "We will follow this same general pattern when we learn each algorithm:\n",
    "\n",
    "- Describe the mathematical foundation for the algorithm  \n",
    "- Use the [scikit-learn](https://scikit-learn.org/stable/) python package to\n",
    "  apply the algorithm to a real world dataset on house prices in Washington state  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed200c29",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Let’s load the dataset and take a quick look at our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e63a94",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "colors = ['#165aa7', '#cb495c', '#fec630', '#bb60d5', '#f47915', '#06ab54', '#002070', '#b27d12', '#007030']\n",
    "\n",
    "# We will import all these here to ensure that they are loaded, but\n",
    "# will usually re-import close to where they are used to make clear\n",
    "# where the functions come from\n",
    "from sklearn import (\n",
    "    linear_model, metrics, neural_network, pipeline, model_selection\n",
    ")\n",
    "\n",
    "url = \"https://datascience.quantecon.org/assets/data/kc_house_data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b2a850",
   "metadata": {},
   "source": [
    "This dataset contains sales prices on houses in King County (which\n",
    "includes Seattle),\n",
    "Washington, from May 2014 to May 2015.\n",
    "\n",
    "The data comes from\n",
    "[Kaggle](https://www.kaggle.com/harlfoxem/housesalesprediction) . Variable definitions and additional documentation are available at that link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e3d00",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "X = df.drop([\"price\", \"date\", \"id\"], axis=1).copy()\n",
    "# convert everything to be a float for later on\n",
    "for col in list(X):\n",
    "    X[col] = X[col].astype(float)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740d6e4",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# notice the log here!\n",
    "y = np.log(df[\"price\"])\n",
    "df[\"log_price\"] = y\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b81405",
   "metadata": {},
   "source": [
    "While we will be using all variables in `X` in our regression models,\n",
    "we will explain some algorithms that use only the `sqft_living` variable.\n",
    "\n",
    "Here’s what the log house price looks like against `sqft_living`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5513d848",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def var_scatter(df, ax=None, var=\"sqft_living\"):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=(8, 6))\n",
    "    df.plot.scatter(x=var , y=\"log_price\", alpha=0.35, s=1.5, ax=ax)\n",
    "\n",
    "    return ax\n",
    "\n",
    "var_scatter(df);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b0ce9b",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Let’s dive in by studying the [“Hello World”](https://en.wikipedia.org/wiki/%22Hello,_World!%22_program) of regression\n",
    "algorithms: linear regression.\n",
    "\n",
    "Suppose we would like to predict the log of the sale price of a home, given\n",
    "only the livable square footage of the home.\n",
    "\n",
    "The linear regression model for this situation is\n",
    "\n",
    "$$\n",
    "\\log(\\text{price}) = \\beta_0 + \\beta_1 \\text{sqft_living} + \\epsilon\n",
    "$$\n",
    "\n",
    "$ \\beta_0 $ and $ \\beta_1 $ are called parameters (also coefficients or\n",
    "weights). The machine learning algorithm is tasked with finding the parameter values\n",
    "that best fit the data.\n",
    "\n",
    "$ \\epsilon $ is the error term. It would be unusual for the observed\n",
    "$ \\log(\\text{price}) $ to be an exact linear function of\n",
    "$ \\text{sqft_living} $. The error term captures the deviation of\n",
    "$ \\log(\\text{price}) $ from a linear function of $ \\text{sqft_living} $.\n",
    "\n",
    "The linear regression algorithm will choose the parameters that minimize the\n",
    "*mean squared error* (MSE) function, which for our example is written.\n",
    "\n",
    "$$\n",
    "\\frac{1}{N} \\sum_{i=1}^N \\left(\\log(\\text{price}_i) - (\\beta_0 + \\beta_1 \\text{sqft_living}_i) \\right)^2\n",
    "$$\n",
    "\n",
    "The output of this algorithm is the straight line (hence linear) that passes as\n",
    "close to the points on our scatter chart as possible.\n",
    "\n",
    "The `sns.lmplot` function below will plot our scatter chart and draw the\n",
    "optimal linear regression line through the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bdea86",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(\n",
    "    data=df, x=\"sqft_living\", y=\"log_price\", height=6,\n",
    "    scatter_kws=dict(s=1.5, alpha=0.35)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b4156e",
   "metadata": {},
   "source": [
    "Let’s use `sklearn` to replicate the figure ourselves.\n",
    "\n",
    "First, we fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb260b6",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# import\n",
    "from sklearn import linear_model\n",
    "\n",
    "# construct the model instance\n",
    "sqft_lr_model = linear_model.LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "sqft_lr_model.fit(X[[\"sqft_living\"]], y)\n",
    "\n",
    "# print the coefficients\n",
    "beta_0 = sqft_lr_model.intercept_\n",
    "beta_1 = sqft_lr_model.coef_[0]\n",
    "\n",
    "print(f\"Fit model: log(price) = {beta_0:.4f} + {beta_1:.4f} sqft_living\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc8d267",
   "metadata": {},
   "source": [
    "Then, we construct the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e916cca8",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "ax = var_scatter(df)\n",
    "\n",
    "# points for the line\n",
    "x = np.array([0, df[\"sqft_living\"].max()])\n",
    "ax.plot(x, beta_0 + beta_1*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2380cc",
   "metadata": {},
   "source": [
    "We can call the `predict` method on our model to evaluate the model at\n",
    "arbitrary points.\n",
    "\n",
    "For example, we can ask the model to predict the sale price of a 5,000-square-foot home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68d0b3d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Note, the argument needs to be two-dimensional. You'll see why shortly.\n",
    "logp_5000 = sqft_lr_model.predict([[5000]])[0]\n",
    "print(f\"The model predicts a 5,000 sq. foot home would cost {np.exp(logp_5000):.2f} dollars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cdb2de",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Use the `sqft_lr_model` that we fit to generate predictions for all data points\n",
    "in our sample.\n",
    "\n",
    "Note that you need to pass a DataFrame (not Series)\n",
    "containing the `sqft_living` column to the `predict`. (See how we passed that to `.fit`\n",
    "above for help)\n",
    "\n",
    "Make a scatter chart with the actual data and the predictions on the same\n",
    "figure. Does it look familiar?\n",
    "\n",
    "When making the scatter for model predictions, we recommend passing\n",
    "`c=\"red\"` and `alpha=0.25` so you can distinguish the data from\n",
    "predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de347c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97d8a8dc",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Use the `metrics.mean_squared_error` function to evaluate the loss\n",
    "function used by `sklearn` when it fits the model for us.\n",
    "\n",
    "Read the docstring to learn which the arguments that function takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c2bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526877f",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression\n",
    "\n",
    "Our example regression above is called a univariate linear\n",
    "regression since it uses a single feature.\n",
    "\n",
    "In practice, more features would be used.\n",
    "\n",
    "Suppose that in addition to `sqft_living`, we also wanted to use the `bathrooms` variable.\n",
    "\n",
    "In this case, the linear regression model is\n",
    "\n",
    "$$\n",
    "\\log(\\text{price}) = \\beta_0 + \\beta_1 \\text{sqft_living} +\n",
    "\\beta_2 \\text{bathrooms} + \\epsilon\n",
    "$$\n",
    "\n",
    "We could keep adding one variable at a time, along with a new $ \\beta_{j} $ coefficient for the :math:`j`th variable, but there’s an easier way.\n",
    "\n",
    "Let’s write this equation in vector/matrix form as\n",
    "\n",
    "$$\n",
    "\\underbrace{\\begin{bmatrix} \\log(\\text{price}_1) \\\\ \\log(\\text{price}_2) \\\\ \\vdots \\\\ \\log(\\text{price}_N)\\end{bmatrix}}_Y = \\underbrace{\\begin{bmatrix} 1 & \\text{sqft_living}_1 & \\text{bathrooms}_1 \\\\ 1 & \\text{sqft_living}_2 & \\text{bathrooms}_2 \\\\ \\vdots & \\vdots & \\vdots \\\\ 1 & \\text{sqft_living}_N & \\text{bathrooms}_N \\end{bmatrix}}_{X} \\underbrace{\\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\end{bmatrix}}_{\\beta} + \\epsilon\n",
    "$$\n",
    "\n",
    "Notice that we can add as many columns to $ X $ as we’d like and the linear\n",
    "regression model will still be written $ Y = X \\beta + \\epsilon $.\n",
    "\n",
    "The mean squared error loss function for the general model is\n",
    "\n",
    "$$\n",
    "\\frac{1}{N} \\sum_{i=1}^N (y_i - X_i \\beta)^2 = \\frac{1}{N} \\| y - X \\beta\\|_2^2\n",
    "$$\n",
    "\n",
    "where $ || \\cdot ||_2 $ is the [l2-norm](http://mathworld.wolfram.com/L2-Norm.html).\n",
    "\n",
    "Let’s fit the linear regression model using all columns in `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed31a6a",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "lr_model = linear_model.LinearRegression()\n",
    "lr_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd9e2d",
   "metadata": {},
   "source": [
    "We just fit a model with 18 variables – just as quickly and easily as\n",
    "fitting the model with 1 variable!\n",
    "\n",
    "Visualizing a 18-dimensional model is rather difficult, but just so we can see how the\n",
    "extra features changed our model, let’s make the log price vs `sqft_living`\n",
    "one more time – this time including the prediction from both of our linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44b843",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "ax = var_scatter(df)\n",
    "\n",
    "def scatter_model(mod, X, ax=None, color=colors[1], x=\"sqft_living\"):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "\n",
    "    ax.scatter(X[x], mod.predict(X), c=color, alpha=0.25, s=1)\n",
    "    return ax\n",
    "\n",
    "scatter_model(lr_model, X, ax, color=colors[1])\n",
    "scatter_model(sqft_lr_model, X[[\"sqft_living\"]], ax, color=colors[2])\n",
    "ax.legend([\"data\", \"full model\", \"sqft model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96df2fca",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "See exercise 3 in the [exercise list](#app-reg-ex)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63ebc9a",
   "metadata": {},
   "source": [
    "# Nonlinear Relationships in Linear Regression\n",
    "\n",
    "While it sounds like an oxymoron, a linear regression model can actually include non-linear features.\n",
    "\n",
    "The distinguishing feature of the linear regression model is that each\n",
    "prediction is generated by taking the dot product (a linear operator) between a\n",
    "feature vector (one row of $ X $) and a coefficient vector ($ \\beta $).\n",
    "\n",
    "There is, however, no restriction on what element we include in our feature\n",
    "vector.\n",
    "\n",
    "Let’s consider an example…\n",
    "\n",
    "Starting from the `sqft_living`-only model, suppose we have a hunch that we\n",
    "should also include the *fraction of square feet above ground*.\n",
    "\n",
    "This last variable can be computed as `sqft_above / sqft_living`.\n",
    "\n",
    "This second feature is nonlinear, but could easily be included as a column in\n",
    "`X`.\n",
    "\n",
    "Let’s see this in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc7b87",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "X2 = X[[\"sqft_living\"]].copy()\n",
    "X2[\"pct_sqft_above\"] = X[\"sqft_above\"] / X[\"sqft_living\"]\n",
    "\n",
    "sqft_above_lr_model = linear_model.LinearRegression()\n",
    "sqft_above_lr_model.fit(X2, y)\n",
    "\n",
    "new_mse = metrics.mean_squared_error(y, sqft_above_lr_model.predict(X2))\n",
    "old_mse = metrics.mean_squared_error(y, sqft_lr_model.predict(X2[[\"sqft_living\"]]))\n",
    "print(f\"The mse changed from {old_mse:.4f} to {new_mse:.4f} by including our new feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30022f5d",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "See exercise 4 in the [exercise list](#app-reg-ex).\n",
    "\n",
    "Determining which columns belong in $ X $ is called *feature\n",
    "engineering* and is a large part of a machine learning practitioner’s job.\n",
    "\n",
    "You may recall from (or will see in) your econometrics course(s) that\n",
    "choosing which control variables to include in a regression model\n",
    "is an important part of applied research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c303355a",
   "metadata": {},
   "source": [
    "### Interpretability\n",
    "\n",
    "Before moving to our next regression model, we want to broach the idea of\n",
    "the **interpretability** of models.\n",
    "\n",
    "An interpretable model is one for which we can analyze the\n",
    "coefficients to explain why it makes its predictions.\n",
    "\n",
    "Recall $ \\beta_0 $ and $ \\beta_1 $ from the univariate model.\n",
    "\n",
    "The interpretation of the model is that $ \\beta_0 $ captures the notion of\n",
    "the average or starting house price and $ \\beta_1 $ is the additional value\n",
    "per square foot.\n",
    "\n",
    "Concretely, we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da18601b",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "beta_0, beta_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9368a480",
   "metadata": {},
   "source": [
    "which means that our model predicts the log price of a house to be 12.22, plus\n",
    "an additional 0.0004 for every square foot.\n",
    "\n",
    "Using more exotic machine learning methods might potentially be more accurate but\n",
    "less interpretable.\n",
    "\n",
    "The accuracy vs interpretability tradeoff is a hot discussion topic, especially relating\n",
    "to concepts like machine learning ethics. This is something you\n",
    "should be aware of as you continue to learn about these techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6486648e",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Some good text books covering the above regression methods:\n",
    "\n",
    "<a id='id27'></a>\n",
    "\\[regB06\\] Christopher M. Bishop. *Pattern Recognition and Machine Learning*. Springer, 2006. URL: [https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf).\n",
    "\n",
    "<a id='id27'></a>\n",
    "\\[regEH16\\] Bradley Efron and Trevor Hastie. *Computer age statistical inference*. Volume 5. Cambridge University Press, 2016. URL: [https://web.stanford.edu/~hastie/CASI/](https://web.stanford.edu/~hastie/CASI/).\n",
    "\n",
    "<a id='id26'></a>\n",
    "\\[regFHT09\\] Jerome Friedman, Trevor Hastie, and Robert Tibshirani. *The elements of statistical learning*. Springer series in statistics, 2009. URL: [https://web.stanford.edu/~hastie/ElemStatLearn/](https://web.stanford.edu/~hastie/ElemStatLearn/).\n",
    "\n",
    "\n",
    "<a id='app-reg-ex'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c006fc0",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef5751a",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Use the `sqft_lr_model` that we fit to generate predictions for all data points\n",
    "in our sample.\n",
    "\n",
    "Note that you need to pass a DataFrame (not Series)\n",
    "containing the `sqft_living` column to the `predict`. (See how we passed that to `.fit`\n",
    "above for help)\n",
    "\n",
    "Make a scatter chart with the actual data and the predictions on the same\n",
    "figure. Does it look familiar?\n",
    "\n",
    "When making the scatter for model predictions, we recommend passing\n",
    "`c=\"red\"` and `alpha=0.25` so you can distinguish the data from\n",
    "predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9a37ff",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Make scatter of data\n",
    "\n",
    "# Make scatter of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fe9608",
   "metadata": {},
   "source": [
    "([back to text](#app-reg-dir1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3b566e",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Use the `metrics.mean_squared_error` function to evaluate the loss\n",
    "function used by `sklearn` when it fits the model for us.\n",
    "\n",
    "Read the docstring to learn which the arguments that function takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43d293",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212e082c",
   "metadata": {},
   "source": [
    "([back to text](#app-reg-dir2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b350f2",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Compare the mean squared error for the `lr_model` and the `sqft_lr_model`.\n",
    "\n",
    "Which model has a better fit? Defend your choice.\n",
    "\n",
    "([back to text](#app-reg-dir3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0626bf6",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Explore how you can improve the fit of the full model by adding additional\n",
    "features created from the existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a8391e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6848ed",
   "metadata": {},
   "source": [
    "([back to text](#app-reg-dir4))"
   ]
  }
 ],
 "metadata": {
  "date": 1689807042.4906044,
  "filename": "regression.md",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "title": "Regression"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
